{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Style Transfer Test","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"CCjaVkpxR7Ku","colab_type":"code","colab":{}},"source":["import torch\n","import torchvision.transforms as transforms\n","from torchvision.utils import save_image\n","import torchvision\n","\n","from google.colab import drive\n","from PIL import Image\n","import os\n","import sys\n","\n","drive.mount(\"/content/gdrive\")\n","\n","# Specify path path of the directory\n","path = \"/content/gdrive/My Drive/Colab Notebooks/GANS/Style Transfer\"\n","sys.path.append(path)\n","\n","from Utils import networks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Rb5eV2Emu2p","colab_type":"code","colab":{}},"source":["# Path for the checkpoint, the vgg state_dict, image folder and device\n","path_check = os.path.join(path, \"StyleTransfer Checkpoint Iter: 120000.tar\")\n","state_vgg = torch.load(os.path.join(path, \"vgg_normalised.pth\"), map_location=torch.device(\"cpu\"))\n","\n","img_dir = \"Images\"\n","\n","device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","network = networks.StyleTransferNetwork(device, state_vgg, train=False, load_fromstate=True, load_path=path_check)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ARudyjWmu5A","colab_type":"code","colab":{}},"source":["transform = transforms.Compose([transforms.Resize(512),\n","                               #transforms.CenterCrop(256),\n","                               transforms.ToTensor()])\n","\n","toPIL = transforms.ToPILImage(mode=\"RGB\")\n","\n","# Path to images\n","style_path, content_path = os.path.join(path, img_dir, \"Laika.png\"), os.path.join(path, img_dir, \"Dag.jpg\")\n","\n","# Load image, convert to RGB, transform, add 0 dimension and move to device\n","style = transform(Image.open(style_path).convert(\"RGB\")).unsqueeze(0).to(device)\n","content = transform(Image.open(content_path).convert(\"RGB\")).unsqueeze(0).to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BGWLzKFp2YI7","colab_type":"code","colab":{}},"source":["# generate image\n","alpha = 1.0\n","out = network(style, content, alpha).cpu()\n","# convert to grid/image\n","out = torchvision.utils.make_grid(out.clamp(min=-1, max=1), nrow=3, scale_each=True, normalize=True)\n","# Make Pil\n","img = toPIL(out)\n","img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZhOhBVfqS0uk","colab_type":"code","colab":{}},"source":["# Save Image\n","name = \"Out.jpg\"\n","save_image(out, os.path.join(path, img_dir, name))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Omt0MfObyRPQ","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}